{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Game_of_Thrones_Script.csv')\n",
    "data = data.drop(columns= ['Release Date', 'Season', 'Episode', 'Episode Title', 'Name'])\n",
    "\n",
    "# Drop rows where 'Sentence' is NaN\n",
    "data = data.dropna(subset=['Sentence'])\n",
    "\n",
    "sentences = data['Sentence']\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "input_sequences = [tokenizer.encode(s, add_special_tokens=True) for s in sentences]\n",
    "\n",
    "max_sequence_len = 25\n",
    "\n",
    "x = [seq[:-1] for seq in input_sequences]\n",
    "y = [seq[1:] for seq in input_sequences]\n",
    "\n",
    "x = pad_sequences(x, maxlen=max_sequence_len - 1, padding='post', truncating='post')\n",
    "y = pad_sequences(y, maxlen=max_sequence_len - 1, padding='post', truncating='post')\n",
    "\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.2, random_state=120)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.13235176  0.99120283  0.3354101  -0.9420722  -0.10202286\n",
      "    0.99478203 -0.5025774  -0.8645322   0.99691     0.0785528\n",
      "   -0.3822061   0.9240771  -0.8990674  -0.4378103   0.29114625\n",
      "   -0.95667857  0.9986632  -0.05168947  0.53361034  0.8457304\n",
      "   -0.34735692  0.937733   -0.91250753  0.4090599  -0.96464837\n",
      "   -0.26354033 -0.65048563 -0.75951856 -0.19102958 -0.9815843\n",
      "    0.2518948  -0.9677546   0.5984721  -0.8011436   0.8286445\n",
      "   -0.5597752   0.954165   -0.29928115  0.9986139  -0.05263342\n",
      "    0.9864277   0.16419612  0.93820924  0.3460686   0.86952573\n",
      "    0.4938876   0.79130185  0.61142564  0.7107539   0.7034407\n",
      "    0.632367    0.77466893  0.5587215   0.82935536  0.49112543\n",
      "    0.87108886  0.4300696   0.90279573  0.3755421   0.9268053\n",
      "    0.32723913  0.9449416   0.28470194  0.9586161   0.24740396\n",
      "    0.9689124   0.21480393  0.9766572   0.18637732  0.98247826\n",
      "    0.16163322  0.9868509   0.1401227   0.9901341   0.12144138\n",
      "    0.9925986   0.10522895  0.994448    0.09116677  0.99583566\n",
      "    0.07897462  0.99687666  0.06840703  0.9976575   0.05924962\n",
      "    0.9982432   0.05131558  0.9986825   0.04444234  0.99901193\n",
      "    0.03848865  0.99925905  0.03333186  0.99944437  0.02886554\n",
      "    0.9995833   0.0249974   0.9996875   0.02164742  0.9997657\n",
      "    0.01874626  0.9998243   0.01623383  0.9998682   0.01405807\n",
      "    0.9999012   0.01217389  0.9999259   0.01054222  0.99994445\n",
      "    0.00912923  0.99995834  0.00790561  0.99996877  0.006846\n",
      "    0.9999766   0.0059284   0.9999824   0.00513379  0.9999868\n",
      "    0.00444568  0.9999901   0.00384981  0.9999926   0.0033338\n",
      "    0.99999446  0.00288695  0.9999958 ]]], shape=(1, 1, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Positional encoding\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = 1 / np.power(10000, (2 * (np.arange(d_model)[np.newaxis, :] // 2)) / np.float32(d_model))\n",
    "    angle_rads[:, 0::2] = np.sin(position * angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(position * angle_rads[:, 1::2])\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "print(positional_encoding(max_sequence_len, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled dot product attention\n",
    "\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "    d_k = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(d_k)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1)\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Head Attention\n",
    "\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.num_depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.num_depth))\n",
    "        return tf.transpose(x, perm=[0,2,1,3])\n",
    "\n",
    "\n",
    "    def call(self, query, key, value, mask):\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        query = self.split_heads(self.wq(query), batch_size)\n",
    "        key = self.split_heads(self.wk(key), batch_size)\n",
    "        value = self.split_heads(self.wv(value), batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(query, key, value, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0,2,1,3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed Forward\n",
    "\n",
    "def point_wise_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,711,488</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,   │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)]      │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,712</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,   │            │ layer_normalizat… │\n",
       "│                     │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)]      │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,712</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ sequential_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28996</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,740,484</span> │ layer_normalizat… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m3,711,488\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │     \u001b[38;5;34m66,048\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m,   │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)]      │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m131,712\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │     \u001b[38;5;34m66,048\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m,   │            │ layer_normalizat… │\n",
       "│                     │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)]      │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m131,712\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ sequential_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m28996\u001b[0m) │  \u001b[38;5;34m3,740,484\u001b[0m │ layer_normalizat… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,848,516</span> (29.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,848,516\u001b[0m (29.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,848,516</span> (29.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,848,516\u001b[0m (29.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 126ms/step - Accuracy: 0.5490 - loss: 3.3281 - val_Accuracy: 0.6829 - val_loss: 1.8901\n",
      "Epoch 2/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 126ms/step - Accuracy: 0.6949 - loss: 1.7211 - val_Accuracy: 0.7310 - val_loss: 1.4938\n",
      "Epoch 3/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 126ms/step - Accuracy: 0.7411 - loss: 1.2533 - val_Accuracy: 0.7440 - val_loss: 1.3479\n",
      "Epoch 4/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 127ms/step - Accuracy: 0.7656 - loss: 0.9985 - val_Accuracy: 0.7535 - val_loss: 1.2920\n",
      "Epoch 5/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 126ms/step - Accuracy: 0.7849 - loss: 0.8389 - val_Accuracy: 0.7554 - val_loss: 1.2615\n",
      "Epoch 6/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 126ms/step - Accuracy: 0.7925 - loss: 0.7672 - val_Accuracy: 0.7575 - val_loss: 1.2693\n",
      "Epoch 7/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 127ms/step - Accuracy: 0.8031 - loss: 0.7036 - val_Accuracy: 0.7545 - val_loss: 1.2858\n",
      "Epoch 8/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 126ms/step - Accuracy: 0.8130 - loss: 0.6534 - val_Accuracy: 0.7583 - val_loss: 1.2734\n",
      "Epoch 9/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 127ms/step - Accuracy: 0.8183 - loss: 0.6248 - val_Accuracy: 0.7618 - val_loss: 1.2779\n",
      "Epoch 10/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 126ms/step - Accuracy: 0.8223 - loss: 0.6040 - val_Accuracy: 0.7601 - val_loss: 1.2754\n",
      "Epoch 11/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 127ms/step - Accuracy: 0.8258 - loss: 0.5820 - val_Accuracy: 0.7614 - val_loss: 1.2889\n",
      "Epoch 12/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 126ms/step - Accuracy: 0.8319 - loss: 0.5549 - val_Accuracy: 0.7605 - val_loss: 1.2859\n",
      "Epoch 13/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 126ms/step - Accuracy: 0.8355 - loss: 0.5360 - val_Accuracy: 0.7614 - val_loss: 1.2974\n",
      "Epoch 14/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 127ms/step - Accuracy: 0.8375 - loss: 0.5276 - val_Accuracy: 0.7630 - val_loss: 1.2988\n",
      "Epoch 15/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 126ms/step - Accuracy: 0.8414 - loss: 0.5072 - val_Accuracy: 0.7611 - val_loss: 1.3208\n",
      "Epoch 16/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 127ms/step - Accuracy: 0.8454 - loss: 0.4929 - val_Accuracy: 0.7594 - val_loss: 1.3268\n",
      "Epoch 17/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 127ms/step - Accuracy: 0.8489 - loss: 0.4778 - val_Accuracy: 0.7588 - val_loss: 1.3483\n",
      "Epoch 18/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 127ms/step - Accuracy: 0.8506 - loss: 0.4700 - val_Accuracy: 0.7611 - val_loss: 1.3429\n",
      "Epoch 19/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 127ms/step - Accuracy: 0.8517 - loss: 0.4667 - val_Accuracy: 0.7619 - val_loss: 1.3653\n",
      "Epoch 20/20\n",
      "\u001b[1m2391/2391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 127ms/step - Accuracy: 0.8544 - loss: 0.4534 - val_Accuracy: 0.7610 - val_loss: 1.3620\n",
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - Accuracy: 0.7647 - loss: 1.3501\n",
      "Test Loss:  1.38184654712677\n",
      "Test Accuracy:  0.7582775950431824\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Plot accuracy\u001b[39;00m\n\u001b[0;32m     51\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     53\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     54\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_layers = 2\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = len(tokenizer.vocab)\n",
    "maximum_position_encoding = max_sequence_len\n",
    "dropout_rate = 0.3\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(max_sequence_len - 1,))\n",
    "\n",
    "x = tf.keras.layers.Embedding(input_vocab_size, d_model)(inputs)\n",
    "x *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "x += positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "for _ in range(num_layers):\n",
    "    attn_output, _ = MultiHeadAttention(d_model, num_heads)(x,x,x,None)\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon= 1e-6)(x + attn_output)\n",
    "    ff_output = point_wise_forward_network(d_model, dff)(x)\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon= 1e-6)(x + ff_output)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(input_vocab_size, activation='softmax')(x)\n",
    "transformer = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "transformer.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "transformer.summary()\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 8\n",
    "\n",
    "history = transformer.fit( \n",
    "                          x_train, \n",
    "                          np.expand_dims(y_train, -1),\n",
    "                          validation_data=(x_val, np.expand_dims(y_val, -1)),\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size\n",
    "                        )\n",
    "\n",
    "loss, accuracy = transformer.evaluate(x_test, np.expand_dims(y_test, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  1.38184654712677\n",
      "Test Accuracy:  0.7582775950431824\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Plot accuracy\u001b[39;00m\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = transformer.evaluate(x_test, np.expand_dims(y_test, -1))\n",
    "\n",
    "print('Test Loss: ', loss)\n",
    "print('Test Accuracy: ', accuracy)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Self Supervised Learning Accuracy and Loss Graph.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict token\n",
    "\n",
    "def predict_next_token(model, tokenizer, text):\n",
    "    encoded_input = tokenizer.encode(text, add_special_tokens=True)\n",
    "    padded_input = pad_sequences([encoded_input], maxlen=max_sequence_len - 1, padding='post', truncating='post')\n",
    "    prediction = model.predict(padded_input)\n",
    "    last_token_prediction = prediction[0, -1, :]\n",
    "    predicted_index = np.argmax(last_token_prediction)\n",
    "\n",
    "    return tokenizer.decode([predicted_index])\n",
    "\n",
    "\n",
    "sentence = \"Syrio says every hurt is a lesson and every lesson makes you better. Tomorrow I'm going to be chasing cats\"\n",
    "\n",
    "predicted_token = predict_next_token(transformer, tokenizer, sentence)\n",
    "\n",
    "print('Predicted Token : ', predicted_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
